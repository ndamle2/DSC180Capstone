{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8747fbc8-03d8-4a41-8d24-0f2109ece48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import networkx as nx\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be78bbf-1544-499b-a30d-2f2a14514174",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"xbar/1/xbar.json.gz\", 'rb') as f:\n",
    "    instances = json.loads(f.read().decode('utf-8'))['instances']\n",
    "\n",
    "with gzip.open(\"cells.json.gz\", 'rb') as f:\n",
    "    cells = json.loads(f.read().decode('utf-8'))\n",
    "\n",
    "conn = np.load(\"xbar/1/xbar_connectivity.npz\")\n",
    "coo = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "adj_matrix = (np.dot(coo.toarray(), coo.toarray().T) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd40d10f-d3af-437f-92dc-e66bf718301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGRCIndex(xloc, yloc, xBoundaryList, yBoundaryList):\n",
    "    \"\"\"\n",
    "    Get the GRC index for a given x, y location.\n",
    "    Args:\n",
    "        xloc (int): X-coordinate in database units.\n",
    "        yloc (int): Y-coordinate in database units.\n",
    "        xBoundaryList (np.ndarray): Array of x-boundaries for GRCs.\n",
    "        yBoundaryList (np.ndarray): Array of y-boundaries for GRCs.\n",
    "    Returns:\n",
    "        tuple: (i, j) indices of the GRC in the grid.\n",
    "    \"\"\"\n",
    "    # Find the GRC index for xloc and yloc\n",
    "    i = np.searchsorted(yBoundaryList, yloc, side='right') - 1\n",
    "    j = np.searchsorted(xBoundaryList, xloc, side='right') - 1\n",
    "    return i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28b751b0-450b-432a-976b-43ac556d803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('xbar/1/xbar_congestion.npz')\n",
    "\n",
    "# Get the index for layer M1\n",
    "lyr = list(data['layerList']).index('M1')\n",
    "\n",
    "# Get boundary arrays for GRCs\n",
    "ybl = data['yBoundaryList']  # y-coordinate boundaries\n",
    "xbl = data['xBoundaryList']  # x-coordinate boundaries\n",
    "\n",
    "for instance in instances:\n",
    "    xloc, yloc = instance['xloc'], instance['yloc']\n",
    "    i, j = getGRCIndex(xloc, yloc, xbl, ybl)  # Compute GRC indices\n",
    "\n",
    "    # Retrieve demand and capacity\n",
    "    demand = data['demand'][lyr][i][j]\n",
    "    capacity = data['capacity'][lyr][i][j]\n",
    "    congestion = demand / capacity if capacity > 0 else demand  # Calculate congestion\n",
    "\n",
    "    # Add congestion data as a feature\n",
    "    instance['demand'] = demand\n",
    "    instance['capacity'] = capacity\n",
    "    instance['congestion'] = congestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5839688c-71f8-4469-9cba-735e747ac07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_virtual_nodes(adj, num_nodes, partition_k=4):\n",
    "    num_vns = partition_k + 1  # partition_k first-level VNs + 1 super-VN\n",
    "    new_size = num_nodes + num_vns\n",
    "    \n",
    "    # Expand adjacency matrix\n",
    "    new_adj = np.zeros((new_size, new_size), dtype=int)\n",
    "    new_adj[:num_nodes, :num_nodes] = adj  # Copy the original adjacency matrix\n",
    "\n",
    "    # Partition nodes\n",
    "    partition_size = num_nodes // partition_k\n",
    "    partitions = [list(range(i * partition_size, (i + 1) * partition_size)) for i in range(partition_k)]\n",
    "\n",
    "    # Add first-level VNs\n",
    "    for i, part in enumerate(partitions):\n",
    "        vn_idx = num_nodes + i\n",
    "        for node in part:\n",
    "            new_adj[node, vn_idx] = 1\n",
    "            new_adj[vn_idx, node] = 1\n",
    "\n",
    "    # Add super-VN\n",
    "    super_vn_idx = num_nodes + partition_k\n",
    "    for i in range(partition_k):\n",
    "        vn_idx = num_nodes + i\n",
    "        new_adj[vn_idx, super_vn_idx] = 1\n",
    "        new_adj[super_vn_idx, vn_idx] = 1\n",
    "\n",
    "    return new_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7b75984-d3f1-415e-a4ec-6671c0f3744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_with_vns = add_virtual_nodes(adj_matrix, conn['shape'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "865b76df-d949-4cb8-9e36-ddd99e0522ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3957, 3957)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_with_vns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ab93ef9-5b63-462c-85d0-6b1b3ae0c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(np.array(np.nonzero(adj_with_vns)), dtype=torch.long)\n",
    "features = torch.rand((adj_with_vns.shape[0], 16))  # Random features for demo\n",
    "data = Data(x=features, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5acc1a2d-9e92-4343-9d3a-c463f6006f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDEHNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(BaseDEHNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.node_mlps = nn.ModuleList([nn.Sequential(nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim), nn.ReLU()) for i in range(num_layers)])\n",
    "        self.net_mlps = nn.ModuleList([nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU()) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, edge_index, adj_matrix):\n",
    "        for i in range(self.num_layers):\n",
    "            # Node Update\n",
    "            net_features = torch.mm(adj_matrix, x)  # Aggregate from hyperedges to nodes\n",
    "            x = x + self.node_mlps[i](net_features)\n",
    "            \n",
    "            # Net Update\n",
    "            node_features = torch.mm(adj_matrix.T, x)  # Aggregate from nodes to hyperedges\n",
    "            x = x + self.net_mlps[i](node_features)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a9a540b-4428-4f66-88a1-5fcba63fc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CongestionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CongestionLoss, self).__init__()\n",
    "\n",
    "    def forward(self, demand, capacity, predicted_net_properties):\n",
    "        congestion = (demand - capacity).clip(min=0)\n",
    "        return torch.mean((predicted_net_properties - congestion)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91329f26-d085-449b-ad02-3de7be4ce4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute GRC index from (xloc, yloc)\n",
    "def getGRCIndex(xloc, yloc, xBoundaryList, yBoundaryList):\n",
    "    \"\"\"\n",
    "    Get the GRC index for a given x, y location.\n",
    "    Args:\n",
    "        xloc (int): X-coordinate in database units.\n",
    "        yloc (int): Y-coordinate in database units.\n",
    "        xBoundaryList (np.ndarray): Array of x-boundaries for GRCs.\n",
    "        yBoundaryList (np.ndarray): Array of y-boundaries for GRCs.\n",
    "    Returns:\n",
    "        tuple: (i, j) indices of the GRC in the grid.\n",
    "    \"\"\"\n",
    "    # Find the GRC index for xloc and yloc\n",
    "    i = np.searchsorted(yBoundaryList, yloc, side='right') - 1\n",
    "    j = np.searchsorted(xBoundaryList, xloc, side='right') - 1\n",
    "    return i, j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfb306f6-b470-44cc-8e39-a999f2500198",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, torch\u001b[38;5;241m.\u001b[39mtensor(adj_with_vns, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(demand, capacity, output\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Example loss aggregation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 12\u001b[0m, in \u001b[0;36mBaseDEHNN.forward\u001b[0;34m(self, x, edge_index, adj_matrix)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Node Update\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     net_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(adj_matrix, x)  \u001b[38;5;66;03m# Aggregate from hyperedges to nodes\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_mlps[i](net_features)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Net Update\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     node_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(adj_matrix\u001b[38;5;241m.\u001b[39mT, x)  \u001b[38;5;66;03m# Aggregate from nodes to hyperedges\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model = BaseDEHNN(input_dim=16, hidden_dim=32, num_layers=3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = CongestionLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index, torch.tensor(adj_with_vns, dtype=torch.float32))\n",
    "    loss = criterion(demand, capacity, output.mean(1))  # Example loss aggregation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0a22125-08f7-41cb-af97-dd6759d01541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 3956, 3956, 3956],\n",
       "        [   0,    1,    2,  ..., 3953, 3954, 3955]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be52c6-24e4-4af9-ab51-997cafca69a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
